---
title: "Constraints on the variation of Chinese phrasal verbs"
output: 
  html_document:
  toc: true
  toc_depth: 2
  toc_float: true
date: "2026-01-12"
---
# Introduction

```{r loading packages, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE }

library(broom.mixed)
library(gt)
library(dplyr)
library(ggplot2)
library(car)         # to calculate VIFs
library(Hmisc)       # to calculate C values
library(party)       # for ctrees and CRF
#install.packages("lattice")
library(lattice)
library(lme4)        # for mixed-effects regression
library(MuMIn)       # for PSeudo R2 measures
library(effects)     # for partial effects plot
library(report)      # for description of various objects
library(parameters)  # to examine model effects
library(performance) # to assess and compare model performance
#install.packages("broom.mixed") #for plotting 
#install.packages("gt")
library(knitr)
#install.packages("gmodels")
library(gmodels)
```


```{r setup, echo=FALSE, eval=TRUE}
PV<-read.csv("merged_out.csv", sep=";", stringsAsFactors=TRUE)
PV_dis <- distinct(PV, Text, .keep_all = TRUE) # removing duplicates
PV_data<- PV_dis[rowSums(is.na(PV_dis) | PV_dis == "") < ncol(PV_dis), ] # removing NA/empty observations
summary(PV_data)
```

##dropping unwanted levels
```{r dropping level, echo=FALSE, eval=FALSE}
PV_data$Response <- droplevels(PV_data$Response)
#PV_data$Structural_priming<-droplevels(PV_data$Structural_priming)
#PV_data$NP_Givenness<-droplevels(PV_data$NP_Givenness)
PV_data$NP_Concreteness<- droplevels(PV_data$NP_Concreteness)
PV_data$NP_Definiteness<- droplevels(PV_data$NP_Definiteness)
PV_data$Time<- droplevels(PV_data$Time)
PV_data$Register<- droplevels(PV_data$Register)
PV_data$Genre<- droplevels(PV_data$Genre)
PV_data$Imperative_conditional<- droplevels(PV_data$Imperative_conditional)
PV_data$le<- droplevels(PV_data$le)
PV_data$Numeric_Classifier<- droplevels(PV_data$Numeric_Classifier)
summary(PV_data)
```

##data overview
```{r data_overview, fig.cap="Figure 1: data overview", echo=TRUE, eval=TRUE, message=FALSO, warning=FALSE}
library(base)
PV_data$Response<-as.factor(PV_data$Response)
PV_data$NP_Length<- as.numeric(PV_data$NP_Length)
#PV_data$Structural_priming<-as.factor(PV_data$Structural_priming)
#PV_data$NP_Givenness<-as.factor(PV_data$NP_Givenness)
PV_data$NP_Concreteness<- as.factor(PV_data$NP_Concreteness)
PV_data$NP_Definiteness<- as.factor(PV_data$NP_Definiteness)
PV_data$Time_num<- as.numeric(PV_data$Time_num)
PV_data$Time<- as.factor(PV_data$Time)
PV_data$Register<- as.factor(PV_data$Register)
PV_data$Genre<- as.factor(PV_data$Genre)
PV_data$Imperative_conditional<- as.factor(PV_data$Imperative_conditional)
PV_data$le<- as.factor(PV_data$le)
PV_data$Numeric_Classifier<- as.factor(PV_data$Numeric_Classifier)

#the frequency of responses
response_counts <- table(PV_data$Response)
piechart<-pie(response_counts, 
    main = "Response Distribution", 
    col = rainbow(length(response_counts)), 
    labels = paste(names(response_counts), response_counts, sep=": ")) 
```

## converting responses to A, B and C types
```{r converting response to types, echo=FALSE, eval=FALSE}

```

## Variables
```{r variables, echo=TRUE, eval=TRUE}
library(knitr)

variables <- data.frame(
    Variable = c("Response", "NP_Length", "NP_Concreteness", "NP_Definiteness", "Time_num", "Register", "Imperative_conditional", "le", "Numeric_Classifier"),
    Type = c("response variable", "numeric", "categorical", "categorical", "numeric", "categorical", "categorical", "categorical", "categorical"),
    Explanation = c("v_chu_n_lai vs. v_chulai_n vs. v_n_chulai", "Object NP length - character numbers ", "Concrete vs. Non-concrete", "Definite vs. Indefinite", "20-year intervals", "3 levels: Written, Spoken and Online", "Yes vs. No", "Absent vs. Present", "Absent vs. Present")
)

# Render as a table
kable(variables, caption = "Table 1: Data Annotation")
```

## Plotting NP_Length vs. Responses
```{r NP_Length Distribution, fig.cap="Figure 2: NP_Length vs. Responses', echo=TRUE, eval=TRUE, fig.width=6, fig.height=4}
PV_data$log_NP_Length <- log(PV_data$NP_Length) 

ggplot(PV_data, aes(x = Response, y = log_NP_Length)) +
  geom_boxplot(fill = "lightblue", color = "black") +
  stat_summary(fun = mean, geom = "point", shape = 18, color = "red", size = 3) +  # Mean (Red Diamond)
  stat_summary(fun = median, geom = "point", shape = 8, color = "blue", size = 3) +  # Median (Blue Star)
  labs(title = "Boxplot of log-transformed NP_Length vs. Response",
       x = "Response",
       y = "log_NP_Length") +
  theme_minimal()
```

#Results
##Conditional Random Forest(CRF)
```{r CRF model fitting, echo = TRUE, eval = TRUE, message=TRUE, warning=TRUE}
PV_data$Response <- droplevels(PV_data$Response)
set.seed(123) # esnures that we can reproduce results
forest = cforest(Response ~ Time_num + log_NP_Length +NP_Concreteness + NP_Definiteness + Genre + Imperative_conditional + le + Numeric_Classifier, data = PV_data)

#### calculate variable importance ranking, takes some time
forest.varimp = varimp(forest, conditional = FALSE) 

#### since Somers'D only works with binary responses,so we use ROC curve (see Hand&Till 2001) to replace C-value. The multiclass AUC is the average of all pairwise AUC.
##get predicted probabilities for all response classes
probs<-do.call(rbind, treeresponse(forest) )
##making sure responses are factors
y<-PV_data$Response
y<-factor(y)
##computing multiclass AUC using pROC
install.packages("pROC")
library(pROC) 
##before assessing AUC, we need to correct the name of porbs matrix to prevent mismatch. CRF tends to rename responses
colnames(probs) <- levels(y)
## now calculating pairwise ROC
levels_y <- levels(y) 
roc_list <- list() 
for (i in 1:(length(levels_y)-1)) { 
  for (j in (i+1):length(levels_y)) { 
    class_i <- levels_y[i] 
    class_j <- levels_y[j] 
    # subset data for the two classes 
    idx <- y %in% c(class_i, class_j) 
    # binary response for this pair 
    y_bin <- factor(y[idx] == class_i, levels = c(FALSE, TRUE)) 
    # probability of class_i 
    p_i <- probs[idx, class_i] 
    roc_list[[paste(class_i, class_j, sep = "_vs_")]] <- roc(y_bin, p_i) 
  } 
}

##plotting ROC objects
plot(roc_list[[1]]) 
plot(roc_list[[2]], add = TRUE, col = "blue") 
plot(roc_list[[3]], add = TRUE, col = "red")

```

## computing H&T multiclass AUC
```{r H&T multiclass AUC, echo=TRUE, eval=TRUE}
##computing pairwise AUCs
sapply(roc_list, auc)

##computing Hand & Till multiclass AUCs
pairwise_auc <- sapply(roc_list, auc) 
multiclass_auc <- mean(pairwise_auc) 
multiclass_auc
```

## plotting CRF

```{r CRF plotting, fig.cap="Figure 5: Factor importance ranking" ,echo = TRUE, eval = TRUE, fig.width=4, fig.height=4}
dotplot(sort(forest.varimp), xlab="Variable Importance", panel = function(x,y){
  panel.dotplot(x, y, col='darkblue', pch=16, cex=1.1)
  panel.abline(v=abs(min(forest.varimp)), col='red',
               lty='longdash', lwd=2)
}
) 
```

##Multinomial regression analysis

```{r Bayesian multinomial regression analysis, echo=TRUE, eval=TRUE}
install.packages ("nnet")
library(nnet)
##modeling fitting

##the default reference response is "V-chu-N-lai"
##setting the reference level of categorical predictors using relevel() function
PV_data$NP_Concreteness <- relevel(PV_data$NP_Concreteness, ref = "Non-concrete")
PV_data$Imperative_conditional<-relevel(PV_data$Imperative_conditional, ref = "No")
PV_data$le<-relevel(PV_data$le, ref="Absent")
PV_data$NP_Definiteness<-relevel(PV_data$NP_Definiteness, ref="Indefinite")
PV_data$Numeric_Classifier<-relevel(PV_data$Numeric_Classifier, ref="Absent")
multinom_model <- multinom( 
  formula = Response ~ Time_num + Genre + log_NP_Length + NP_Concreteness + NP_Definiteness + Imperative_conditional + le + Numeric_Classifier, data = PV_data)
summary(multinom_model)

```
```{r model assessment, echo=TRUE, eval=TRUE}
##overall model fitting
library(pscl) 
pR2(multinom_model)

## multiclass AUC
library(pROC) 
multiclass.roc(PV_data$Response, predict(multinom_model, type="prob"))
```
```{r coefficients, echo=TRUE, eval=TRUE}
##extract tidy coefficients
library(broom) 
library(dplyr) 
library(knitr)
coef_table <- tidy(multinom_model) %>% 
  mutate( 
    z_value = estimate / std.error, 
    p_value = 2 * (1 - pnorm(abs(z_value))) 
    ) %>% 
  select(y.level, term, estimate, std.error,z_value, p_value) 
# Print a nice table 
kable( 
  coef_table, 
  digits = 4, caption = "Multinomial Regression Coefficients with Significance" 
  )
```

##deriving V-chulai-N vs. V-N-chulai logit
```{r coefficnets of the third regression, echo=FALSE, eval=FALSE}
library(dplyr) 
library(knitr)
## extracting coefficients and variance-covariance matrices
coef_mat<-coef(multinom_model)
##then identifying outcome names
outcomes<-rownames(coef_mat)
outcomes
vc_mat<-vcov(multinom_model)
## deriving the comparison of V-N-chulai (C) vs. V-chulai-N (B)
coef_C_vs_B<-coef_mat[outcomes[2],]-coef_mat[outcomes[1],]
###computing std.errors for the third comparison
##### Helper function to extract block matrices from vcov 
get_block <- function(vcov_matrix, outcome_name, coef_names) { 
  idx <- grep(paste0("^", outcome_name, ":"), rownames(vcov_matrix)) 
  vcov_matrix[idx, idx] 
  }
####extract blocks for  V-N-chulai and V-chulai-N
block_B <- get_block(vc_mat, outcomes[1], colnames(coef_mat)) 
block_C <- get_block(vc_mat, outcomes[2], colnames(coef_mat))
####extract cross-variance block
idx_B <- grep(paste0("^", outcomes[1], ":"), rownames(vc_mat)) 
idx_C <- grep(paste0("^", outcomes[2], ":"), rownames(vc_mat)) 
block_CB <- vc_mat[idx_C, idx_B]
####variance of C-B
var_C_vs_B <- block_C + block_B - 2 * block_CB 
se_C_vs_B <- sqrt(diag(var_C_vs_B))
####z- and p-values
z_C_vs_B <- coef_C_vs_B / se_C_vs_B 
p_C_vs_B <- 2 * (1 - pnorm(abs(z_C_vs_B)))
####results:
results_C_vs_B <- data.frame( 
  term = names(coef_C_vs_B), 
  estimate = coef_C_vs_B, 
  std.error = se_C_vs_B, 
  z.value = z_C_vs_B, 
  p.value = p_C_vs_B )
####printing results
kable( 
  results_C_vs_B, 
  digits = 4, 
  caption = "Derived Binary Logit: V-N-chulai (C) vs. V-chulai-N (B)" )
```

