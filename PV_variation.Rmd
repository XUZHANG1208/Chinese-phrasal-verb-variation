---
title: "Constraints on the variation of Chinese phrasal verbs"
output: 
  html_document:
  toc: true
  toc_depth: 2
  toc_float: true
  number_sections: true
date: "2026-01-12"
---
# Introduction

```{r loading packages, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE }

library(broom.mixed)
library(gt)
library(dplyr)
library(ggplot2)
library(car)         # to calculate VIFs
library(Hmisc)       # to calculate C values
library(party)       # for ctrees and CRF
#install.packages("lattice")
library(lattice)
library(lme4)        # for mixed-effects regression
library(MuMIn)       # for PSeudo R2 measures
library(effects)     # for partial effects plot
library(report)      # for description of various objects
library(parameters)  # to examine model effects
library(performance) # to assess and compare model performance
#install.packages("broom.mixed") #for plotting 
#install.packages("gt")
library(knitr)
#install.packages("gmodels")
library(gmodels)
```


```{r setup, echo=FALSE, eval=TRUE}
PV<-read.csv("merged_out.csv", sep=";", stringsAsFactors=TRUE)
PV_dis <- distinct(PV, Text, .keep_all = TRUE) # removing duplicates
PV_data<- PV_dis[rowSums(is.na(PV_dis) | PV_dis == "") < ncol(PV_dis), ] # removing NA/empty observations
summary(PV_data)
```

##dropping unwanted levels
```{r dropping level, echo=FALSE, eval=FALSE}
PV_data$Response <- droplevels(PV_data$Response)
#PV_data$Structural_priming<-droplevels(PV_data$Structural_priming)
#PV_data$NP_Givenness<-droplevels(PV_data$NP_Givenness)
PV_data$NP_Concreteness<- droplevels(PV_data$NP_Concreteness)
PV_data$NP_Definiteness<- droplevels(PV_data$NP_Definiteness)
PV_data$NP_Givenness<- droplevels(PV_data$NP_Givenness)
PV_data$Structural_Priming<-droplevels(PV_data$Structural_Priming)
PV_data$Time<- droplevels(PV_data$Time)
PV_data$Register<- droplevels(PV_data$Register)
PV_data$Genre<- droplevels(PV_data$Genre)
PV_data$Imperative_conditional<- droplevels(PV_data$Imperative_conditional)
PV_data$le<- droplevels(PV_data$le)
PV_data$Numeric_Classifier<- droplevels(PV_data$Numeric_Classifier)
summary(PV_data)
```

##data overview
```{r data_overview, fig.cap="Figure 1: data overview", echo=TRUE, eval=TRUE, message=FALSO, warning=FALSE}
library(base)
PV_data$Response<-as.factor(PV_data$Response)
PV_data$NP_Length<- as.numeric(PV_data$NP_Length)
#PV_data$Structural_priming<-as.factor(PV_data$Structural_priming)
#PV_data$NP_Givenness<-as.factor(PV_data$NP_Givenness)
PV_data$NP_Concreteness<- as.factor(PV_data$NP_Concreteness)
PV_data$NP_Definiteness<- as.factor(PV_data$NP_Definiteness)
PV_data$NP_Givenness<- as.factor(PV_data$NP_Givenness)
PV_data$Structural_Priming<-as.factor(PV_data$Structural_Priming)
PV_data$Time_num<- as.numeric(PV_data$Time_num)
PV_data$Time<- as.factor(PV_data$Time)
PV_data$Register<- as.factor(PV_data$Register)
PV_data$Genre<- as.factor(PV_data$Genre)
PV_data$Imperative_conditional<- as.factor(PV_data$Imperative_conditional)
PV_data$le<- as.factor(PV_data$le)
PV_data$Numeric_Classifier<- as.factor(PV_data$Numeric_Classifier)

#the frequency of responses
response_counts <- table(PV_data$Response)
piechart<-pie(response_counts, 
    main = "Response Distribution", 
    col = rainbow(length(response_counts)), 
    labels = paste(names(response_counts), response_counts, sep=": ")) 
```

## converting responses to A, B and C types
```{r converting response to types, echo=FALSE, eval=FALSE}
PV_data$Response_recode<-factor(
  PV_data$Response,
  levels=c("V-N-chulai", "V-chu-N-lai", "V-chulai-N"), # A,B,C are sequenced according to the position of the NP object
  labels=c("A","B", "C")
)
```

## Variables
```{r variables, echo=TRUE, eval=TRUE}
library(knitr)

variables <- data.frame(
    Variable = c("Response", "NP_Length", "NP_Concreteness", "NP_Definiteness","NP_Givenness","Structural_Priming", "Time_num", "Register", "Imperative_conditional", "le", "Numeric_Classifier"),
    Type = c("response variable", "numeric", "categorical", "categorical","categorical","categorical", "numeric", "categorical", "categorical", "categorical", "categorical"),
    Explanation = c("v_chu_n_lai vs. v_chulai_n vs. v_n_chulai", "Object NP length - character numbers ", "Concrete vs. Non-concrete", "Definite vs. Indefinite","New vs.Given","Yes vs.No", "20-year intervals", "3 levels: Written, Spoken and Online", "Yes vs. No", "Absent vs. Present", "Absent vs. Present")
)

# Render as a table
kable(variables, caption = "Table 1: Data Annotation")
```

## Plotting NP_Length vs. Responses
```{r NP_Length Distribution, fig.cap="Figure 2: NP_Length vs. Responses', echo=TRUE, eval=TRUE, fig.width=6, fig.height=4}
PV_data$log_NP_Length <- log(PV_data$NP_Length) 

ggplot(PV_data, aes(x = Response, y = log_NP_Length)) +
  geom_boxplot(fill = "lightblue", color = "black") +
  stat_summary(fun = mean, geom = "point", shape = 18, color = "red", size = 3) +  # Mean (Red Diamond)
  stat_summary(fun = median, geom = "point", shape = 8, color = "blue", size = 3) +  # Median (Blue Star)
  labs(title = "Boxplot of log-transformed NP_Length vs. Response",
       x = "Response",
       y = "log_NP_Length") +
  theme_minimal()
```

#Results
##Conditional Random Forest(CRF)
```{r CRF model fitting, echo = TRUE, eval = TRUE, message=TRUE, warning=TRUE}
PV_data$Response <- droplevels(PV_data$Response)
set.seed(123) # esnures that we can reproduce results
forest = cforest(Response ~ Time_num + log_NP_Length +NP_Concreteness + NP_Definiteness +NP_Givenness +Structural_Priming + Genre + Imperative_conditional + le + Numeric_Classifier, data = PV_data)

#### calculate variable importance ranking, takes some time
forest.varimp = varimp(forest, conditional = FALSE) 

#### since Somers'D only works with binary responses,so we use ROC curve (see Hand&Till 2001) to replace C-value. The multiclass AUC is the average of all pairwise AUC.
##get predicted probabilities for all response classes
probs<-do.call(rbind, treeresponse(forest) )
##making sure responses are factors
y<-PV_data$Response
y<-factor(y)
##computing multiclass AUC using pROC
install.packages("pROC")
library(pROC) 
##before assessing AUC, we need to correct the name of porbs matrix to prevent mismatch. CRF tends to rename responses
colnames(probs) <- levels(y)
## now calculating pairwise ROC
levels_y <- levels(y) 
roc_list <- list() 
for (i in 1:(length(levels_y)-1)) { 
  for (j in (i+1):length(levels_y)) { 
    class_i <- levels_y[i] 
    class_j <- levels_y[j] 
    # subset data for the two classes 
    idx <- y %in% c(class_i, class_j) 
    # binary response for this pair 
    y_bin <- factor(y[idx] == class_i, levels = c(FALSE, TRUE)) 
    # probability of class_i 
    p_i <- probs[idx, class_i] 
    roc_list[[paste(class_i, class_j, sep = "_vs_")]] <- roc(y_bin, p_i) 
  } 
}

##plotting ROC objects
plot(roc_list[[1]]) 
plot(roc_list[[2]], add = TRUE, col = "blue") 
plot(roc_list[[3]], add = TRUE, col = "red")

```

## computing H&T multiclass AUC
```{r H&T multiclass AUC, echo=TRUE, eval=TRUE}
##computing pairwise AUCs
sapply(roc_list, auc)

##computing Hand & Till multiclass AUCs
pairwise_auc <- sapply(roc_list, auc) 
multiclass_auc <- mean(pairwise_auc) 
multiclass_auc
```

## plotting CRF

```{r CRF plotting, fig.cap="Figure 5: Factor importance ranking" ,echo = TRUE, eval = TRUE, fig.width=6 fig.height=4}
dotplot(sort(forest.varimp), xlab="Variable Importance", panel = function(x,y){
  panel.dotplot(x, y, col='darkblue', pch=16, cex=1.1)
  panel.abline(v=abs(min(forest.varimp)), col='red',
               lty='longdash', lwd=2)
}
) 
```

##Making variable importance more interpretable
Since log_NP_length dominates the importance ranking to a great degree, the tree is severally compressed leaving the other predictors marginal and their importance non-interpretable. To better understand the importance of the other variables, we plot the importance without NP_length.
```{r Importance ranking without NP_length, echo=TRUE, eval=TRUE}
top_var<-names(which.max(forest.varimp))
imp_others<-forest.varimp[ names(forest.varimp) !=top_var ]
dotplot(sort(imp_others), xlab="Variable Importance (without NP_length)", panel = function(x,y){
  panel.dotplot(x, y, col='darkblue', pch=16, cex=1.1)
  panel.abline(v=abs(min(forest.varimp)), col='red',
               lty='longdash', lwd=2)
}
) 
```

##Multinomial regression analysis

```{r Bayesian multinomial regression analysis, echo=TRUE, eval=TRUE}
install.packages ("nnet")
library(nnet)
##modeling fitting

##the default reference response is "V-chu-N-lai" -B 
##setting the reference level of categorical predictors using relevel() function
PV_data$Response_recode<-relevel(PV_data$Response_recode, ref="B")
PV_data$NP_Concreteness <- relevel(PV_data$NP_Concreteness, ref = "Non-concrete")
PV_data$Imperative_conditional<-relevel(PV_data$Imperative_conditional, ref = "No")
PV_data$le<-relevel(PV_data$le, ref="Absent")
PV_data$NP_Definiteness<-relevel(PV_data$NP_Definiteness, ref="Indefinite")
PV_data$NP_Givenness<-relevel(PV_data$NP_Givenness, ref="New")
PV_data$Structural_Priming<-relevel(PV_data$Structural_Priming, ref="No")
PV_data$Numeric_Classifier<-relevel(PV_data$Numeric_Classifier, ref="Absent")
multinom_model <- multinom( 
  formula = Response_recode ~ Time_num + log_NP_Length +NP_Concreteness + NP_Definiteness +NP_Givenness +Structural_Priming + Genre + Imperative_conditional + le + Numeric_Classifier, data = PV_data)
summary(multinom_model)

```
```{r model assessment, echo=TRUE, eval=TRUE}
##overall model fitting
library(pscl) 
pR2(multinom_model)

## multiclass AUC
library(pROC) 
multiclass.roc(PV_data$Response, predict(multinom_model, type="prob"))
```
```{r coefficients, echo=TRUE, eval=TRUE}
##extract tidy coefficients
library(broom) 
library(dplyr) 
library(knitr)
coef_table <- tidy(multinom_model) %>% 
  mutate( 
    z_value = estimate / std.error, 
    p_value = 2 * (1 - pnorm(abs(z_value))) 
    ) %>% 
  select(y.level, term, estimate, std.error,z_value, p_value) 

kable( 
  coef_table, 
  digits = 4, caption = "Multinomial Regression Coefficients" 
  )
```

##deriving V-chulai-N vs. V-N-chulai logit
```{r coefficnets of the third regression, echo=FALSE, eval=FALSE}
library(dplyr) 
library(knitr)
## extracting coefficients and variance-covariance matrices
coef_mat<-coef(multinom_model)
##then identifying outcome names
outcomes<-rownames(coef_mat)
outcomes
vc_mat<-vcov(multinom_model)
## deriving the comparison of V-N-chulai (B) vs. V-chulai-N (C)
coef_AC<-coef_mat[outcomes[1],]-coef_mat[outcomes[2],]
###computing std.errors for the third comparison
##### Helper function to extract block matrices from vcov 
get_block <- function(vcov_matrix, outcome_name, coef_names) { 
  idx <- grep(paste0("^", outcome_name, ":"), rownames(vcov_matrix)) 
  vcov_matrix[idx, idx] 
  }
####extract blocks for  V-N-chulai(A) and V-chulai-N(B)
block_A <- get_block(vc_mat, outcomes[1], colnames(coef_mat)) 
block_C <- get_block(vc_mat, outcomes[2], colnames(coef_mat))
####extract cross-variance block
idx_A <- grep(paste0("^", outcomes[1], ":"), rownames(vc_mat)) 
idx_C <- grep(paste0("^", outcomes[2], ":"), rownames(vc_mat)) 
block_AC <- vc_mat[idx_A, idx_C]
####variance of C-B
var_AC <- block_A + block_C - 2 * block_AC 
se_AC <- sqrt(diag(var_AC))
####z- and p-values
z_AC <- coef_AC / se_AC 
p_AC <- 2 * (1 - pnorm(abs(z_AC)))
####results:
results_AC <- data.frame( 
  term = names(coef_AC),
  estimate = coef_AC, 
  std.error = se_AC, 
  z.value = z_AC, 
  p.value = p_AC )
####printing results
kable( 
  results_AC, 
  digits = 4, 
  caption = "Derived Binary Logit: V-N-chulai (A) vs. V-chulai-N (C)" )
```

### result presentation
```{r extracting only coefficients with significant ones in bold, echo=TRUE, eval=TRUE}
coefs <- summary(multinom_model)$coefficients 
ses <- summary(multinom_model)$standard.errors 
zvals <- coefs / ses 
pvals <- 2 * (1 - pnorm(abs(zvals)))
#function to bold the significant coefficients
bold_sig <- function(beta, p, alpha = 0.05) {
  ifelse(p < alpha,
         paste0("**", round(beta, 3), "**"),
         round(beta, 3))
}

table_AB <- data.frame(
  term = colnames(coefs),
  A_vs_B   = mapply(bold_sig, coefs["A", ], pvals["A", ])
)

table_CB <- data.frame(
  term = colnames(coefs),
  C_vs_B   = mapply(bold_sig, coefs["C", ], pvals["C", ])
)

results_AC$estimate_fmt <- ifelse(
  results_AC$p.value < 0.05,
  paste0("**", round(results_AC$estimate, 3), "**"),
  round(results_AC$estimate, 3)
)

table_AC <- data.frame(
  term = results_AC$term,
  A_vs_C = results_AC$estimate_fmt
)

final_table <- Reduce(function(x, y) merge(x, y, by = "term"),
                           list(table_AB, table_CB, table_AC))

final_table

library(knitr)
library(kableExtra)

final_table %>%
  kable(escape = FALSE, 
        caption = "Multinomial Regression Modeling") %>%
  column_spec(1, width = "5cm") %>%   # term column
  column_spec(2, width = "4cm") %>%   
  column_spec(3, width = "4cm") %>%  
  column_spec(4, width = "4cm")      

```

